{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b617ae075494be81",
   "metadata": {},
   "source": [
    "## 多个 feas_iti 且最后一趟列车 id 相同的乘客\n",
    "\n",
    "|           |     rid | iti_id |    path_id | seg_id | train_id | board_ts | alight_ts |\n",
    "| :-------- | ------: | -----: | ---------: | -----: | -------: | -------: | --------: |\n",
    "| 93194730  | 1525794 |      2 | 1076103701 |      2 | 10301630 |    65071 |     65670 |\n",
    "| 8610761   |  119014 |      6 | 1101102701 |      3 | 11002833 |    30045 |     30791 |\n",
    "| 18578209  |  230428 |      6 | 1053108503 |      2 | 10401849 |    29715 |     30255 |\n",
    "| 72855273  | 1321497 |      3 | 1110112802 |      1 | 10401844 |    60803 |     61537 |\n",
    "| 105488240 | 1781873 |      2 | 1028106602 |      2 | 10401738 |    69396 |     69625 |\n",
    "| 90908613  | 1485498 |      2 | 1023112302 |      2 | 10702370 |    64374 |     64780 |\n",
    "| 91388272  | 1494286 |      1 | 1104111501 |      2 | 10702247 |    65070 |     65278 |\n",
    "| 53621559  |  957712 |      6 | 1121102503 |      3 | 10401786 |    49174 |     50141 |\n",
    "| 19767473  |  243641 |      1 | 1081103901 |      2 | 10702323 |    29509 |     31141 |\n",
    "| 107978876 | 1880069 |      2 | 1129107002 |      1 | 10201226 |    73278 |     74154 |\n",
    "| 106615427 | 1817923 |      1 | 1027110801 |      2 | 10301362 |    71471 |     73514 |\n",
    "| 76737269  | 1359494 |      1 | 1099102101 |      2 | 10301421 |    64071 |     65266 |\n",
    "| 100422001 | 1661221 |      5 | 1061108702 |      1 | 10100270 |    66558 |     66886 |\n",
    "| 2408620   |   41409 |      2 | 1111106502 |      1 | 10401886 |    25727 |     25836 |\n",
    "| 101105912 | 1675451 |      1 | 1110101301 |      1 | 10401914 |    66944 |     67031 |\n",
    "| 92513072  | 1514419 |      3 | 1097110302 |      3 | 10200839 |    65302 |     65408 |\n",
    "| 81121188  | 1412555 |      1 | 1061109504 |      2 | 10201199 |    63371 |     63480 |\n",
    "| 108069499 | 1886032 |      1 | 1032108201 |      1 | 10200950 |    73568 |     75192 |\n",
    "| 73737366  | 1331466 |      1 | 1086110901 |      2 | 10702414 |    61616 |     62107 |\n",
    "| 48046191  |  811513 |      3 | 1076103602 |      3 | 10301265 |    42747 |     43084 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95fb1bdb39167193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:35:46.312158Z",
     "start_time": "2025-04-25T02:35:46.296116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading file: results\\egress\\etd_1.csv\n",
      "[INFO] Reading file: results\\transfer\\ttd_1.csv\n",
      "[INFO] Reading file: results\\network\\pathvia.pkl\n",
      "[INFO] Reading file: results\\network\\platform.csv\n",
      "[INFO] Reading file: results\\trajectory\\left.pkl\n",
      "(46637884, 7)\n",
      "(1195446, 7)\n",
      "(16339032, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>iti_id</th>\n",
       "      <th>path_id</th>\n",
       "      <th>seg_id</th>\n",
       "      <th>train_id</th>\n",
       "      <th>board_ts</th>\n",
       "      <th>alight_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>1120101001</td>\n",
       "      <td>1</td>\n",
       "      <td>10702170</td>\n",
       "      <td>21132</td>\n",
       "      <td>22747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>1120101001</td>\n",
       "      <td>1</td>\n",
       "      <td>10702170</td>\n",
       "      <td>25273</td>\n",
       "      <td>26962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285</td>\n",
       "      <td>3</td>\n",
       "      <td>1120101001</td>\n",
       "      <td>1</td>\n",
       "      <td>10702186</td>\n",
       "      <td>21797</td>\n",
       "      <td>23422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>285</td>\n",
       "      <td>4</td>\n",
       "      <td>1120101001</td>\n",
       "      <td>1</td>\n",
       "      <td>10702186</td>\n",
       "      <td>25949</td>\n",
       "      <td>27655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>285</td>\n",
       "      <td>5</td>\n",
       "      <td>1120101001</td>\n",
       "      <td>1</td>\n",
       "      <td>10702207</td>\n",
       "      <td>22652</td>\n",
       "      <td>24277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109949952</th>\n",
       "      <td>2046865</td>\n",
       "      <td>2</td>\n",
       "      <td>1097101501</td>\n",
       "      <td>1</td>\n",
       "      <td>10100645</td>\n",
       "      <td>85287</td>\n",
       "      <td>85823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109949955</th>\n",
       "      <td>2046868</td>\n",
       "      <td>1</td>\n",
       "      <td>1097101501</td>\n",
       "      <td>1</td>\n",
       "      <td>10100421</td>\n",
       "      <td>84945</td>\n",
       "      <td>85481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109949956</th>\n",
       "      <td>2046868</td>\n",
       "      <td>2</td>\n",
       "      <td>1097101501</td>\n",
       "      <td>1</td>\n",
       "      <td>10100645</td>\n",
       "      <td>85287</td>\n",
       "      <td>85823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109949965</th>\n",
       "      <td>2046883</td>\n",
       "      <td>1</td>\n",
       "      <td>1129101001</td>\n",
       "      <td>1</td>\n",
       "      <td>10702289</td>\n",
       "      <td>85531</td>\n",
       "      <td>85741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109949966</th>\n",
       "      <td>2046883</td>\n",
       "      <td>2</td>\n",
       "      <td>1129101001</td>\n",
       "      <td>1</td>\n",
       "      <td>10702573</td>\n",
       "      <td>85035</td>\n",
       "      <td>85245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46637884 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               rid  iti_id     path_id  seg_id  train_id  board_ts  alight_ts\n",
       "2              285       1  1120101001       1  10702170     21132      22747\n",
       "3              285       2  1120101001       1  10702170     25273      26962\n",
       "4              285       3  1120101001       1  10702186     21797      23422\n",
       "5              285       4  1120101001       1  10702186     25949      27655\n",
       "6              285       5  1120101001       1  10702207     22652      24277\n",
       "...            ...     ...         ...     ...       ...       ...        ...\n",
       "109949952  2046865       2  1097101501       1  10100645     85287      85823\n",
       "109949955  2046868       1  1097101501       1  10100421     84945      85481\n",
       "109949956  2046868       2  1097101501       1  10100645     85287      85823\n",
       "109949965  2046883       1  1129101001       1  10702289     85531      85741\n",
       "109949966  2046883       2  1129101001       1  10702573     85035      85245\n",
       "\n",
       "[46637884 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src import config\n",
    "from src.utils import *\n",
    "from src.globals import *\n",
    "from src.itinerary import *\n",
    "\n",
    "config.load_config()\n",
    "\n",
    "wtd = WalkTimeDisModel(etd=get_etd(), ttd=get_ttd())\n",
    "\n",
    "left = read_(config.CONFIG[\"results\"][\"left\"], show_timer=False)\n",
    "print(left.shape)\n",
    "print(left.drop_duplicates(\"rid\").shape)\n",
    "print(left.drop_duplicates([\"rid\", \"iti_id\"]).shape)\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3dd1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Calculating entry walk distribution for all itineraries...\n",
      "[INFO] Reading file: data\\AFC.pkl\n",
      "[INFO] Calculating egress walk distribution for all itineraries...\n",
      "[INFO] Calculating transfer walk distribution for all itineraries...\n"
     ]
    }
   ],
   "source": [
    "# Calculate entry walk distribution for all itineraries in `left`\n",
    "print(\"[INFO] Calculating entry walk distribution for all itineraries...\")\n",
    "df_ent = cal_entry_dis_all(wtd=wtd, left=left)\n",
    "df_ent[\"seg_id\"] = 0  # set entry seg_id to 0\n",
    "\n",
    "# Calculate egress walk distribution for all itineraries in `left`\n",
    "print(\"[INFO] Calculating egress walk distribution for all itineraries...\")\n",
    "df_egr = cal_egress_dis_all(wtd=wtd, left=left)\n",
    "df_egr[\"seg_id\"] = -1  # set egress seg_id to -1\n",
    "\n",
    "# Calculate transfer walk distribution for all itineraries in `left`\n",
    "print(\"[INFO] Calculating transfer walk distribution for all itineraries...\")\n",
    "df_trans = cal_transfer_dis_all(wtd=wtd, left=left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1fdb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rid', 'iti_id', 'path_id', 'board_ts', 'entry_pp_id', 'ts1',\n",
      "       'entry_time', 'dis', 'seg_id'],\n",
      "      dtype='object') Index(['rid', 'iti_id', 'path_id', 'alight_ts', 'egress_pp_id', 'ts2',\n",
      "       'egress_time', 'dis', 'seg_id'],\n",
      "      dtype='object') Index(['rid', 'iti_id', 'path_id', 'seg_id', 'alight_ts', 'board_ts',\n",
      "       'board_ts', 'transfer_time', 'transfer_type', 'pp_id_min', 'pp_id_max',\n",
      "       'dis'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_ent.columns, df_egr.columns, df_trans.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec0110e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Calculating entry walk distribution for all itineraries...\n",
      "[INFO] Calculating egress walk distribution for all itineraries...\n",
      "[INFO] Calculating transfer walk distribution for all itineraries...\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidIndexError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     32\u001b[39m df_trans = cal_transfer_dis_all(wtd=wtd, left=left)\n\u001b[32m     33\u001b[39m df_trans = df_trans.rename(\n\u001b[32m     34\u001b[39m     columns={\n\u001b[32m     35\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpp_id_min\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpp_id1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrid\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33miti_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpath_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mseg_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mt1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mt2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpp_id1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpp_id2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdis\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m ]]\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m df = pd.concat([df_ent, df_egr, df_trans], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     46\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUNNY\\miniconda3\\envs\\syc\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    382\u001b[39m op = _Concatenator(\n\u001b[32m    383\u001b[39m     objs,\n\u001b[32m    384\u001b[39m     axis=axis,\n\u001b[32m   (...)\u001b[39m\u001b[32m    392\u001b[39m     sort=sort,\n\u001b[32m    393\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUNNY\\miniconda3\\envs\\syc\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[39m, in \u001b[36m_Concatenator.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    678\u001b[39m         obj_labels = obj.axes[\u001b[32m1\u001b[39m - ax]\n\u001b[32m    679\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels.equals(obj_labels):\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m             indexers[ax] = obj_labels.get_indexer(new_labels)\n\u001b[32m    682\u001b[39m     mgrs_indexers.append((obj._mgr, indexers))\n\u001b[32m    684\u001b[39m new_data = concatenate_managers(\n\u001b[32m    685\u001b[39m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m.new_axes, concat_axis=\u001b[38;5;28mself\u001b[39m.bm_axis, copy=\u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m    686\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUNNY\\miniconda3\\envs\\syc\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[39m, in \u001b[36mIndex.get_indexer\u001b[39m\u001b[34m(self, target, method, limit, tolerance)\u001b[39m\n\u001b[32m   3882\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_method(method, limit, tolerance)\n\u001b[32m   3884\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_as_unique:\n\u001b[32m-> \u001b[39m\u001b[32m3885\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m._requires_unique_msg)\n\u001b[32m   3887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) == \u001b[32m0\u001b[39m:\n\u001b[32m   3888\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array([], dtype=np.intp)\n",
      "\u001b[31mInvalidIndexError\u001b[39m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# Calculate entry walk distribution for all itineraries in `left`\n",
    "print(\"[INFO] Calculating entry walk distribution for all itineraries...\")\n",
    "df_ent = cal_entry_dis_all(wtd=wtd, left=left)\n",
    "df_ent[\"seg_id\"] = 0  # set entry seg_id to 0\n",
    "df_ent = df_ent.rename(\n",
    "    columns={\n",
    "        \"ts1\": \"t1\",\n",
    "        \"board_ts\": \"t2\",\n",
    "        \"entry_time\": \"time\",\n",
    "        \"entry_pp_id\": \"pp_id1\"}\n",
    ")[[\n",
    "    \"rid\", 'iti_id', 'path_id', 'seg_id', 't1', 't2', 'pp_id1', 'time', 'dis'\n",
    "]]\n",
    "\n",
    "# Calculate egress walk distribution for all itineraries in `left`\n",
    "print(\"[INFO] Calculating egress walk distribution for all itineraries...\")\n",
    "df_egr = cal_egress_dis_all(wtd=wtd, left=left)\n",
    "df_egr[\"seg_id\"] = -1  # set egress seg_id to -1\n",
    "df_egr = df_egr.rename(\n",
    "    columns={\n",
    "        \"alight_ts\": \"t1\",\n",
    "        \"ts2\": \"t2\",\n",
    "        \"egress_time\": \"time\",\n",
    "        \"egress_pp_id\": \"pp_id2\",\n",
    "    }\n",
    ")[[\n",
    "    \"rid\", \"iti_id\", \"path_id\", \"seg_id\", \"t1\", \"t2\", \"pp_id2\", \"time\", \"dis\"\n",
    "]]\n",
    "\n",
    "# Calculate transfer walk distribution for all itineraries in `left`\n",
    "print(\"[INFO] Calculating transfer walk distribution for all itineraries...\")\n",
    "df_trans = cal_transfer_dis_all(wtd=wtd, left=left)\n",
    "df_trans = df_trans.rename(\n",
    "    columns={\n",
    "        \"pp_id_min\": \"pp_id1\",\n",
    "        \"pp_id_max\": \"pp_id2\",\n",
    "        \"transfer_time\": \"time\",\n",
    "        \"alight_ts\": \"t1\",\n",
    "        \"board_ts\": \"t2\"\n",
    "    }\n",
    ")[[\n",
    "    \"rid\", \"iti_id\", \"path_id\", \"seg_id\", \"t1\", \"t2\", \"pp_id1\", \"pp_id2\", \"time\", \"dis\"\n",
    "]]\n",
    "\n",
    "df = pd.concat([df_ent, df_egr, df_trans], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabbacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16339032 entries, 2 to 109949966\n",
      "Data columns (total 9 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   rid      int32  \n",
      " 1   iti_id   int32  \n",
      " 2   path_id  int32  \n",
      " 3   seg_id   int64  \n",
      " 4   t1       int64  \n",
      " 5   t2       int32  \n",
      " 6   pp_id1   int64  \n",
      " 7   time     int64  \n",
      " 8   dis      float64\n",
      "dtypes: float64(1), int32(4), int64(4)\n",
      "memory usage: 1.5 GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16339032 entries, 2 to 109949966\n",
      "Data columns (total 9 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   rid      int32  \n",
      " 1   iti_id   int32  \n",
      " 2   path_id  int32  \n",
      " 3   seg_id   int64  \n",
      " 4   t1       int32  \n",
      " 5   t2       int64  \n",
      " 6   pp_id2   int64  \n",
      " 7   time     int64  \n",
      " 8   dis      float64\n",
      "dtypes: float64(1), int32(4), int64(4)\n",
      "memory usage: 1.5 GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30298852 entries, 0 to 30298851\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   rid      int32  \n",
      " 1   iti_id   int32  \n",
      " 2   path_id  object \n",
      " 3   seg_id   int8   \n",
      " 4   t1       int32  \n",
      " 5   t2       int32  \n",
      " 6   t2       float64\n",
      " 7   pp_id1   int64  \n",
      " 8   pp_id2   int64  \n",
      " 9   time     int64  \n",
      " 10  dis      float64\n",
      "dtypes: float64(2), int32(4), int64(3), int8(1), object(1)\n",
      "memory usage: 1.8+ GB\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidIndexError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m df_egr.info()\n\u001b[32m      3\u001b[39m df_trans.info()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m pd.concat([df_ent, df_egr, df_trans], join=\u001b[33m\"\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m\"\u001b[39m, ignore_index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUNNY\\miniconda3\\envs\\syc\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    382\u001b[39m op = _Concatenator(\n\u001b[32m    383\u001b[39m     objs,\n\u001b[32m    384\u001b[39m     axis=axis,\n\u001b[32m   (...)\u001b[39m\u001b[32m    392\u001b[39m     sort=sort,\n\u001b[32m    393\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUNNY\\miniconda3\\envs\\syc\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[39m, in \u001b[36m_Concatenator.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    678\u001b[39m         obj_labels = obj.axes[\u001b[32m1\u001b[39m - ax]\n\u001b[32m    679\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels.equals(obj_labels):\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m             indexers[ax] = obj_labels.get_indexer(new_labels)\n\u001b[32m    682\u001b[39m     mgrs_indexers.append((obj._mgr, indexers))\n\u001b[32m    684\u001b[39m new_data = concatenate_managers(\n\u001b[32m    685\u001b[39m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m.new_axes, concat_axis=\u001b[38;5;28mself\u001b[39m.bm_axis, copy=\u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m    686\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUNNY\\miniconda3\\envs\\syc\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[39m, in \u001b[36mIndex.get_indexer\u001b[39m\u001b[34m(self, target, method, limit, tolerance)\u001b[39m\n\u001b[32m   3882\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_method(method, limit, tolerance)\n\u001b[32m   3884\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_as_unique:\n\u001b[32m-> \u001b[39m\u001b[32m3885\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m._requires_unique_msg)\n\u001b[32m   3887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) == \u001b[32m0\u001b[39m:\n\u001b[32m   3888\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array([], dtype=np.intp)\n",
      "\u001b[31mInvalidIndexError\u001b[39m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "df_ent.info()\n",
    "df_egr.info()\n",
    "df_trans.info()\n",
    "pd.concat([df_ent, df_egr, df_trans], join=\"outer\", ignore_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
